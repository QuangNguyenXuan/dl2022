{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-26 12:02:22.519940: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-26 12:02:22.523467: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-26 12:02:22.523725: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-26 12:02:22.524089: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-01-26 12:02:22.524711: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-26 12:02:22.524964: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-26 12:02:22.525208: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-26 12:02:22.846364: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-26 12:02:22.846632: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-26 12:02:22.846867: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-26 12:02:22.847129: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5703 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 32, 32, 64)        1792      \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 32, 32, 64)        36928     \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 32, 32, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 16, 16, 64)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 16, 16, 128)       73856     \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 16, 16, 128)       147584    \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 16, 16, 128)       147584    \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 8, 8, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 8, 8, 256)         295168    \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 4, 4, 256)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 4096)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                40970     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,960,970\n",
      "Trainable params: 1,960,970\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-26 12:02:24.604262: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8201\n",
      "2022-01-26 12:02:25.811407: I tensorflow/stream_executor/cuda/cuda_blas.cc:1774] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196/196 [==============================] - 10s 39ms/step - loss: 2.3185 - accuracy: 0.0994 - val_loss: 2.3163 - val_accuracy: 0.1000\n",
      "Epoch 2/200\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 2.3131 - accuracy: 0.0974 - val_loss: 2.3171 - val_accuracy: 0.1000\n",
      "Epoch 3/200\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 2.3119 - accuracy: 0.0989 - val_loss: 2.3136 - val_accuracy: 0.1000\n",
      "Epoch 4/200\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 2.3096 - accuracy: 0.1013 - val_loss: 2.3123 - val_accuracy: 0.1000\n",
      "Epoch 5/200\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 2.3100 - accuracy: 0.0992 - val_loss: 2.3134 - val_accuracy: 0.1000\n",
      "Epoch 6/200\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 2.3095 - accuracy: 0.0996 - val_loss: 2.3122 - val_accuracy: 0.1000\n",
      "Epoch 7/200\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 2.3091 - accuracy: 0.1005 - val_loss: 2.3106 - val_accuracy: 0.1000\n",
      "Epoch 8/200\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 2.3092 - accuracy: 0.1009 - val_loss: 2.3067 - val_accuracy: 0.1000\n",
      "Epoch 9/200\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 2.3089 - accuracy: 0.0979 - val_loss: 2.3089 - val_accuracy: 0.1000\n",
      "Epoch 10/200\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 2.3072 - accuracy: 0.1004 - val_loss: 2.3087 - val_accuracy: 0.1000\n",
      "Epoch 11/200\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 2.3061 - accuracy: 0.0979 - val_loss: 2.3048 - val_accuracy: 0.1000\n",
      "Epoch 12/200\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 2.3053 - accuracy: 0.0983 - val_loss: 2.3054 - val_accuracy: 0.1000\n",
      "Epoch 13/200\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 2.3049 - accuracy: 0.0978 - val_loss: 2.3043 - val_accuracy: 0.1000\n",
      "Epoch 14/200\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 2.3038 - accuracy: 0.0985 - val_loss: 2.3042 - val_accuracy: 0.1000\n",
      "Epoch 15/200\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 2.3036 - accuracy: 0.0986 - val_loss: 2.3031 - val_accuracy: 0.1000\n",
      "Epoch 16/200\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 2.3033 - accuracy: 0.0989 - val_loss: 2.3033 - val_accuracy: 0.1000\n",
      "Epoch 17/200\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 2.3032 - accuracy: 0.0992 - val_loss: 2.3029 - val_accuracy: 0.1000\n",
      "Epoch 18/200\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 2.3031 - accuracy: 0.0979 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
      "Epoch 19/200\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 2.3029 - accuracy: 0.0996 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
      "Epoch 20/200\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 2.3029 - accuracy: 0.0984 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
      "Epoch 21/200\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 2.3028 - accuracy: 0.0983 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 22/200\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 2.3028 - accuracy: 0.0983 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 23/200\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 2.3028 - accuracy: 0.0977 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 24/200\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 2.3028 - accuracy: 0.0991 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 25/200\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 2.3027 - accuracy: 0.0993 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 26/200\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 2.3027 - accuracy: 0.0986 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 27/200\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 2.3027 - accuracy: 0.0978 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 28/200\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 2.3027 - accuracy: 0.0985 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 29/200\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 2.3027 - accuracy: 0.0967 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 30/200\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 2.3027 - accuracy: 0.0963 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 31/200\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 2.3027 - accuracy: 0.0979 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 32/200\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 2.3027 - accuracy: 0.0974 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 33/200\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 2.3027 - accuracy: 0.0975 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 34/200\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 2.3027 - accuracy: 0.0992 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 35/200\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 2.3027 - accuracy: 0.0983 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 36/200\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 2.3027 - accuracy: 0.0978 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 37/200\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 2.3026 - accuracy: 0.0979 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 38/200\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 2.3026 - accuracy: 0.0966 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 39/200\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 2.3026 - accuracy: 0.0960 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 40/200\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 2.3026 - accuracy: 0.0950 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 41/200\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 2.3026 - accuracy: 0.0977 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 42/200\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 2.3026 - accuracy: 0.0971 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 43/200\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 2.3026 - accuracy: 0.0963 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 44/200\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 2.3026 - accuracy: 0.0975 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 45/200\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 2.3026 - accuracy: 0.0962 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 46/200\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 2.3026 - accuracy: 0.0969 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 47/200\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 2.3026 - accuracy: 0.0989 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 48/200\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 2.3026 - accuracy: 0.0962 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 49/200\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 2.3026 - accuracy: 0.0987 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 50/200\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 2.3026 - accuracy: 0.0967 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 51/200\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 2.3026 - accuracy: 0.0975 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 52/200\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 2.3026 - accuracy: 0.0992 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 53/200\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 2.3026 - accuracy: 0.0983 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 54/200\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 2.3026 - accuracy: 0.0967 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 55/200\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 2.3026 - accuracy: 0.0963 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 56/200\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 2.3026 - accuracy: 0.0974 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 57/200\n",
      "196/196 [==============================] - 7s 37ms/step - loss: 2.3026 - accuracy: 0.0976 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 58/200\n",
      "117/196 [================>.............] - ETA: 2s - loss: 2.3026 - accuracy: 0.0989"
     ]
    }
   ],
   "source": [
    "# sigmoid for cifar-10: adding layers\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "# set seed\n",
    "tf.random.set_seed(1234)\n",
    "\n",
    "# data preparation\n",
    "cifar10 = tf.keras.datasets.cifar10\n",
    "(x_train, y_train),(x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# normalize\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "# model\n",
    "model = keras.models.Sequential()\n",
    "model.add(tf.keras.Input(shape=(32, 32, 3)))\n",
    "\n",
    "model.add(keras.layers.Conv2D(64, (3, 3), strides=1, padding='same', activation='sigmoid'))\n",
    "model.add(keras.layers.Conv2D(64, (3, 3), strides=1, padding='same', activation='sigmoid'))\n",
    "model.add(keras.layers.Conv2D(64, (3, 3), strides=1, padding='same', activation='sigmoid'))\n",
    "model.add(keras.layers.MaxPooling2D(2))\n",
    "\n",
    "model.add(keras.layers.Conv2D(128, (3, 3), strides=1, padding='same', activation='sigmoid'))\n",
    "model.add(keras.layers.Conv2D(128, (3, 3), strides=1, padding='same', activation='sigmoid'))\n",
    "model.add(keras.layers.Conv2D(128, (3, 3), strides=1, padding='same', activation='sigmoid'))\n",
    "model.add(keras.layers.MaxPooling2D(2))\n",
    "\n",
    "model.add(keras.layers.Conv2D(256, (3, 3), strides=1, padding='same', activation='sigmoid'))\n",
    "model.add(keras.layers.Conv2D(256, (3, 3), strides=1, padding='same', activation='sigmoid'))\n",
    "model.add(keras.layers.Conv2D(256, (3, 3), strides=1, padding='same', activation='sigmoid'))\n",
    "model.add(keras.layers.MaxPooling2D(2))\n",
    "\n",
    "# flatten\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(512, activation='sigmoid'))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "model.summary()\n",
    "\n",
    "# training\n",
    "opt = tf.keras.optimizers.Adam(0.0001)\n",
    "model.compile(optimizer=opt, metrics=['accuracy'], loss='sparse_categorical_crossentropy')\n",
    "\n",
    "history = model.fit(x_train, y_train, batch_size=256, validation_data=(x_test, y_test), \n",
    "                    epochs=200, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['loss'], label = \"train_loss\")\n",
    "plt.plot(history.history['val_loss'], label = \"val_loss\")\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['accuracy'], label = \"train_accuracy\")\n",
    "plt.plot(history.history['val_accuracy'], label = \"val_accuracy\")\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
